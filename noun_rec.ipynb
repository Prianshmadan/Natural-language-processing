{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the no of keywords \n",
    "##chunking\n",
    "is a process of extracting phrases from unstructured text, which means analyzing a sentence to identify the constituents(Noun Groups, Verbs, verb groups, etc.) However, it does not specify their internal structure, nor their role in the main sentence.\n",
    "\n",
    "It works on top of POS tagging. It uses POS-tags as input and provides chunks as output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using regular exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.chunk.regexp import tag_pattern2re_pattern\n",
    "# print(\"chunk pattern\",tag_pattern2re_pattern())\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S -> NP VP\n",
    "\n",
    "NP -> {Det N,Pro,PN}\n",
    "\n",
    "VP -> V (NP) (PP) (Adv)\n",
    "\n",
    "PP -> P NP\n",
    "\n",
    "AP -> A (PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Rama', 'NNP'), ('killed', 'VBD'), ('Ravana', 'NNP'), ('to', 'TO'), ('save', 'VB'), ('Sita', 'NNP'), ('from', 'IN'), ('Lanka', 'NNP'), ('and', 'CC'), ('The', 'DT'), ('legend', 'NN'), ('of', 'IN'), ('the', 'DT'), ('Ramayan', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('most', 'RBS'), ('popular', 'JJ'), ('Indian', 'JJ'), ('epic', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.chunk import RegexpParser\n",
    " \n",
    "# Introducing the Pattern\n",
    "grammar = \"NP:{<DT>?<JJ>*<NN>*}\"\n",
    "\n",
    "sen=(\"Rama killed Ravana to save Sita from Lanka and The legend of the Ramayan is the most popular Indian epic\")\n",
    "\n",
    "sent=word_tokenize(sen)\n",
    "tags=pos_tag(sent)\n",
    "\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(tags) \n",
    "print(tags)\n",
    "result.draw()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chunkers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Natural language processing\\noun_rec.ipynb Cell 7\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Natural%20language%20processing/noun_rec.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mchunkers\u001b[39;00m \u001b[39mimport\u001b[39;00m ClassifierChunker\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Natural%20language%20processing/noun_rec.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m treebank_chunk\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Natural%20language%20processing/noun_rec.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_data \u001b[39m=\u001b[39m treebank_chunk\u001b[39m.\u001b[39mchunked_sents()[:\u001b[39m3000\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chunkers'"
     ]
    }
   ],
   "source": [
    "from chunkers import ClassifierChunker\n",
    "from nltk.corpus import treebank_chunk\n",
    " \n",
    "train_data = treebank_chunk.chunked_sents()[:3000]\n",
    "test_data = treebank_chunk.chunked_sents()[3000:]\n",
    " \n",
    "# initializing\n",
    "chunker = ClassifierChunker(train_data)\n",
    " \n",
    "# evaluation\n",
    "score = chunker.evaluate(test_data)\n",
    " \n",
    "a = score.accuracy()\n",
    "p = score.precision()\n",
    "r = recall\n",
    "   \n",
    "print (\"Accuracy of ClassifierChunker : \", a)\n",
    "print (\"\\nPrecision of ClassifierChunker : \", p)\n",
    "print (\"\\nRecall of ClassifierChunker : \", r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using corpus reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words : \n",
      " [Tree('NP', [(\"('Rama',\", None), (\"'NNP'),\", None), (\"('killed',\", None), (\"'VBD'),\", None), (\"('Ravana',\", None), (\"'NNP'),\", None), (\"('to',\", None), (\"'TO'),\", None), (\"('save',\", None), (\"'VB'),\", None), (\"('Sita',\", None), (\"'NNP'),\", None), (\"('from',\", None), (\"'IN'),\", None), (\"('Lanka',\", None), (\"'NNP'),\", None), (\"('and',\", None), (\"'CC'),\", None), (\"('The',\", None), (\"'DT'),\", None), (\"('legend',\", None), (\"'NN'),\", None), (\"('of',\", None), (\"'IN'),\", None), (\"('the',\", None), (\"'DT'),\", None), (\"('Ramayan',\", None), (\"'NNP'),\", None), (\"('is',\", None), (\"'VBZ'),\", None), (\"('the',\", None), (\"'DT'),\", None), (\"('most',\", None), (\"'RBS'),\", None), (\"('popular',\", None), (\"'JJ'),\", None), (\"('Indian',\", None), (\"'JJ'),\", None), (\"('epic',\", None), (\"'NN')\", None)])]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus.reader.chunked import ChunkedCorpusReader\n",
    "x = ChunkedCorpusReader('.', r'.*\\.chunk')\n",
    " \n",
    "words = x.chunked_words()\n",
    "print (\"Words : \\n\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2364832518.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    Chunked Sentence = x.chunked_sents()\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Chunked Sentence = x.chunked_sents()\n",
    "print (\"Chunked Sentence : \\n\", tagged_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Natural language processing\\noun_rec.ipynb Cell 11\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Natural%20language%20processing/noun_rec.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m para \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mchunked_paras()()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Natural%20language%20processing/noun_rec.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mpara : \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, para)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "para = x.chunked_paras()()\n",
    "print (\"para : \\n\", para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
